# Homework 5

Name: Qing Teng

UNI: qt2126

Date: April 23rd, 2019

## Problem 1

### 1.

**(a)**

**Descriptions of variables:**

$x_k$: the <u>state</u> vector describing the location and orientation of the vehicle at time instant $k$

$u_k$: the <u>control</u> vector applied at time $k-1$ to drive the vehicle to state $x_k$ at time $k$ (similar to <u>velocity</u>)

$m$: the location vector of the <u>landmarks</u>

$z_k$: the <u>observations</u> of the locations of the landmarks at time $k$

**Descriptions of distributions:**

$P(x_k|x_{k-1}, u_k)$: <u>state transition</u> model, i.e. the probability distribution of state $x_k$ at time $k$ given the preceding state $x_{k-1}$ and the applied control $u_k$.

$P(z_k|x_k, m)$: <u>observation</u> model, i.e. the probability distribution of observing $z_k$ given the current state $x_k$ and the map $m$

$P(x_{k-1}, m|Z_{0:k-1}, U_{0:k-1}, x_0)$: the <u>prior</u> belief distribution of the robot's state and the map

$P(x_k, m|Z_{0:k-1}, U_{0:k}, x_0)$: the belief distribution of the robot's state and the map <u>after</u> taking an action but <u>before</u> making an observation

$P(x_k, m|Z_{0:k}, U_{0:k}, x_0)$: the <u>posterior</u> belief distribution of the robot's state and the map

**Equation (4):**

The belief distribution of the robot's state and the map <u>after</u> taking an action but <u>before</u> making an observation at time $k$, conditioned on 1) the observations from time $0$ to time $k-1$ , 2) the actions from time $0$ to time $k$ and 3) the initial state $x_0$, <u>is equal to</u> the <u>sum</u> of the transition probabilities of state $x_k$ given preceding state $x_{k-1}$ and applied control $u_k$ <u>times</u> the <u>prior</u> distributions of the robot's state and the map at time $k-1$, conditioned on 1) the observations from time $0$ to time $k-1$ , 2) the actions from time $0$ to time $k-1$ and 3) the initial state $x_0$. (This might be the longest sentence I ever wrote.)

**Equation (5):**

The <u>posterior</u> belief distribution of the robot's state and the map at time $k$, conditioned on 1) the observations from time $0$ to time $k$ , 2) the actions from time $0$ to time $k$ and 3) the initial state $x_0$, <u>is equal to</u> the <u>product</u> of 1) the probability of observing $z_k$ given the current state $x_k$ and map $m$ and 2) the belief distribution of the robot's state and the map <u>after</u> taking an action but <u>before</u> making an observation at time $k$, conditioned on 1) the observations from time $0$ to time $k-1$ , 2) the actions from time $0$ to time $k$ and 3) the initial state $x_0$, divided by the probability of observing $z_k$ at time $k$ given previous observations from time $0$ to time $k-1$ and previous actions from time $0$ to time $k$, which is constant.

**(b)**

**Equation (4):**
$$
P(x_k, m|Z_{0:k-1}, U_{0:k}, x_0)
\\
=\int P(x_k, m, x_{k-1}| Z_{0:k-1}, U_{0:k}, x_0)dx_{k-1}\text{		(Law of total probability)}
\\
=\int P(x_k|m, x_{k-1}, Z_{0:k-1}, U_{0:k}, x_0)\times P(x_{k-1}, m|Z_{0:k-1}, U_{0:k}, x_0)dx_{k-1}\text{		(Chain rule)}
\\
=\int P(x_k|x_{k-1}, u_k)\times P(x_{k-1}, m|Z_{0:k-1}, U_{0:k-1}, x_0)dx_{k-1}\text{		(Markov assumption)}
$$
**Equation (5):**
$$
P(x_k, m|Z_{0:k}, U_{0:k}, x_0)
\\
=\frac{P(z_k|x_k, m, Z_{0:k-1}, U_{0:k}, x_0)P(x_k, m|Z_{0:k-1}, U_{0:k}, x_0)}{P(z_k|Z_{0:k-1}, U_{0:k}, x_0)}\text{		(Bayes' theorem)}
\\
=\frac{P(z_k|x_k, m, Z_{0:k-1}, U_{0:k}, x_0))P(x_k, m|Z_{0:k-1}, U_{0:k}, x_0)}{P(z_k|Z_{0:k-1}, U_{0:k})}\text{		(Observation is constant)}
\\
=\frac{P(z_k|x_k, m)P(x_k, m|Z_{0:k-1}, U_{0:k}, x_0)}{P(z_k|Z_{0:k-1}, U_{0:k})}\text{		(Markov assumption)}
$$

### 2.

**(a)**

The robot is planer, so the dimension of $\hat{x}_{k|k}$ is $3*1$.

There are $n$ landmarks and each is specified by its $x$ and $y$ position, so the dimension of $\hat{m}_k$ is $2n*1$.

The observations can be represented by $\rho$ and $\theta$, so the dimension of $z_k$ should be $2n * 1$.

The other dimensions can be deduced by the equations. They are:

$P_{k|k}$: $(2n+3) * (2n+3)$

$Q_k$: $3 * 3$

$R_k$: $2n * 2n$

$\nabla f$: $3 * 3$

$\nabla h$: $2n * (2n+3)$

$S_k$: $2n * 2n$

$W_k$: $(2n+3) * 2n$

After fixing the typo, Equation (10) becomes $\begin{bmatrix}\hat{x}_{k|k}\\\hat{m}_k\end{bmatrix}=\begin{bmatrix}\hat{x}_{k|k-1}\\\hat{m}_{k-1}\end{bmatrix}+W_k\begin{bmatrix}z_k-h(\hat{x}_{k|k-1}, \hat{m}_{k-1})\end{bmatrix}$.

**(b)**

**Relationship:**

$P_{xx, k|k-1}$ consists of the upper-left $3*3$ box of $P_{k|k-1}$. In other words, $P_{k|k-1}=\begin{bmatrix}P_{xx} & P_{xm} \\ P^T_{xm} & P_{mm}\end{bmatrix}_{k|k-1}$ .

**Obtaining $P_{k|k-1}$**

$P_{mm}$ is the covariance (uncertainty estimate) of the landmarks and it should not change when the robot moves. So $P_{mm, k | k-1} = P_{mm, k-1 | k-1}$.

$P_{xm, k|k-1}$ can be calculated by $\nabla fP_{xm, k-1 | k-1}$.

$P^T_{xm, k|k-1}$ is the transpose of $P_{xm, k|k-1}$, so $P^T_{xm, k|k-1}=P^T_{xm, k-1 | k-1}\nabla f^T$.

So we can obtain $P_{k|k-1}$ by $\begin{bmatrix}P_{xx, k | k-1} & \nabla fP_{xm, k-1 | k-1} \\ P^T_{xm, k-1 | k-1}\nabla f^T & P_{mm, k-1 | k-1}\end{bmatrix}$.

### 3.

**(a)**

Given the robot trajectory, in a Bayes network diagram, the path between different landmarks would be <u>blocked</u> by the pose states. Therefore map landmarks are independent conditioned on the robot trajectory.

According to the paper, "SIS with resampling can produce reasonable statistics only for systems that 'exponentially forget' their past (i.e., systems whose process noise cause the state at time $k$ to become increasingly independent of preceding states)." In other words, the loss of historical state information caused by resampling will cause the algorithm to produce inaccurate results unless the states are highly independent.

**(b)**

FastSLAM 1.0 uses the motion model for the proposal distribution. The intuition is to "move" the particles based on the most recent action $u_t$, then weight them according to the observation model (normalize). FastSLAM 2.0 uses the motion model <u>as well as</u> the current observation for the proposal distribution. The intuition is to move the particles directly such that their distribution reflects the desired distribution. The advantage of FastSLAM 2.0 is that for each particle, it gives the smallest possible variance in weight conditioned upon the available information.

Sampling according to Equation (16) means to generate samples based on the probability distribution in Equation (16), namely, the state transition probability. Sampling according to Equation (18) means to generate samples based on the probability distribution in Equation (18), namely, the posterior distribution.

**(c)**

No, because according to the paper, the approximation error grows with time (and inherent joint space), increasing the variation in sample weights, and degrading statistical accuracy. Resampling reinstates uniform weighting, so it is an important step in making FastSLAM work properly.

